{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"cleaned-data.csv\")\n",
    "\n",
    "df = df.set_index(pd.DatetimeIndex(df['year'])).drop(['year'], axis=1)\n",
    "df['electionDate'] = pd.to_datetime(df['electionDate'], format='%B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfams = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parfam_pivot = pd.pivot_table(df, index=['countryname'], columns='parfam', aggfunc=np.sum)\n",
    "\n",
    "parfam_pivot.to_csv('missingParfam.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Austria (missing 60, 80, 90, 98)\n",
    "#Belgium (missing 60, 80, 95, 98)\n",
    "#Bulgaria (missing 20, 95)\n",
    "\n",
    "df2 = df.loc[(df['countryname']=='Bulgaria')] \n",
    "\n",
    "#Parfam 10\n",
    "df_10 = df2.loc[(df2['parfam']==10)] #Filter to just this parfam\n",
    "df_10_min = df_10.index.min() #Get the first year for reindexing between election dates\n",
    "df_10_unique = df_10[~df_10.index.duplicated(keep='first')] #Remove dupes\n",
    "df_10_dupes = df_10[df_10.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_10 = pd.date_range(df_10_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_10_fill = df_10_unique.reindex(index=idx_10, method='ffill') #add additional years & forward fill\n",
    "df_10_final = df_10_fill.append(df_10_dupes) #add back dupes\n",
    "\n",
    "##Parfam 20##\n",
    "# df_20 = df2.loc[(df2['parfam']==20)] #Filter to just this parfam\n",
    "# df_20_min = df_20.index.min() #Get the first year for reindexing between election dates\n",
    "# df_20_unique = df_20[~df_20.index.duplicated(keep='first')] #Remove dupes\n",
    "# df_20_dupes = df_20[df_20.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "# idx_20 = pd.date_range(df_20_min, '2020', freq='YS') #set the year range for reindexing\n",
    "# df_20_fill = df_20_unique.reindex(index=idx_20, method='ffill')\n",
    "# df_20_final = df_20_fill.append(df_20_dupes)\n",
    "\n",
    "##Parfam 30##\n",
    "df_30 = df2.loc[(df2['parfam']==30)] #Filter to just this parfam\n",
    "df_30_min = df_30.index.min() #Get the first year for reindexing between election dates\n",
    "df_30_unique = df_30[~df_30.index.duplicated(keep='first')] #Remove dupes\n",
    "df_30_dupes = df_30[df_30.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_30 = pd.date_range(df_30_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_30_fill = df_30_unique.reindex(index=idx_30, method='ffill')\n",
    "df_30_final = df_30_fill.append(df_30_dupes)\n",
    "\n",
    "##Parfam 40##\n",
    "df_40 = df2.loc[(df2['parfam']==40)] #Filter to just this parfam\n",
    "df_40_min = df_40.index.min() #Get the first year for reindexing between election dates\n",
    "df_40_unique = df_40[~df_40.index.duplicated(keep='first')] #Remove dupes\n",
    "df_40_dupes = df_40[df_40.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_40 = pd.date_range(df_40_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_40_fill = df_40_unique.reindex(index=idx_40, method='ffill')\n",
    "df_40_final = df_40_fill.append(df_40_dupes)\n",
    "\n",
    "##Parfam 50##\n",
    "df_50 = df2.loc[(df2['parfam']==50)] #Filter to just this parfam\n",
    "df_50_min = df_50.index.min() #Get the first year for reindexing between election dates\n",
    "df_50_unique = df_50[~df_50.index.duplicated(keep='first')] #Remove dupes\n",
    "df_50_dupes = df_50[df_50.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_50 = pd.date_range(df_50_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_50_fill = df_50_unique.reindex(index=idx_50, method='ffill')\n",
    "df_50_final = df_50_fill.append(df_50_dupes)\n",
    "\n",
    "##Parfam 60##\n",
    "df_60 = df2.loc[(df2['parfam']==60)] #Filter to just this parfam\n",
    "df_60_min = df_60.index.min() #Get the first year for reindexing between election dates\n",
    "df_60_unique = df_60[~df_60.index.duplicated(keep='first')] #Remove dupes\n",
    "df_60_dupes = df_60[df_60.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_60 = pd.date_range(df_60_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_60_fill = df_60_unique.reindex(index=idx_60, method='ffill')\n",
    "df_60_final = df_60_fill.append(df_60_dupes)\n",
    "\n",
    "##Parfam 70##\n",
    "df_70 = df2.loc[(df2['parfam']==70)] #Filter to just this parfam\n",
    "df_70_min = df_70.index.min() #Get the first year for reindexing between election dates\n",
    "df_70_unique = df_70[~df_70.index.duplicated(keep='first')] #Remove dupes\n",
    "df_70_dupes = df_70[df_70.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_70 = pd.date_range(df_70_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_70_fill = df_70_unique.reindex(index=idx_70, method='ffill')\n",
    "df_70_final = df_70_fill.append(df_70_dupes)\n",
    "\n",
    "##Parfam 80##\n",
    "df_80 = df2.loc[(df2['parfam']==80)] #Filter to just this parfam\n",
    "df_80_min = df_80.index.min() #Get the first year for reindexing between election dates\n",
    "df_80_unique = df_80[~df_80.index.duplicated(keep='first')] #Remove dupes\n",
    "df_80_dupes = df_80[df_80.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_80 = pd.date_range(df_80_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_80_fill = df_80_unique.reindex(index=idx_80, method='ffill')\n",
    "df_80_final = df_80_fill.append(df_80_dupes)\n",
    "\n",
    "##Parfam 90##\n",
    "df_90 = df2.loc[(df2['parfam']==90)] #Filter to just this parfam\n",
    "df_90_min = df_90.index.min() #Get the first year for reindexing between election dates\n",
    "df_90_unique = df_90[~df_90.index.duplicated(keep='first')] #Remove dupes\n",
    "df_90_dupes = df_90[df_90.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_90 = pd.date_range(df_90_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_90_fill = df_90_unique.reindex(index=idx_90, method='ffill')\n",
    "df_90_final = df_90_fill.append(df_90_dupes)\n",
    "\n",
    "##Parfam 95##\n",
    "# df_95 = df2.loc[(df2['parfam']==95)] #Filter to just this parfam\n",
    "# df_95_min = df_95.index.min() #Get the first year for reindexing between election dates\n",
    "# df_95_unique = df_95[~df_95.index.duplicated(keep='first')] #Remove dupes\n",
    "# df_95_dupes = df_95[df_95.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "# idx_95 = pd.date_range(df_95_min, '2020', freq='YS') #set the year range for reindexing\n",
    "# df_95_fill = df_95_unique.reindex(index=idx_95, method='ffill')\n",
    "# df_95_final = df_95_fill.append(df_95_dupes)\n",
    "\n",
    "##Parfam 98##\n",
    "df_98 = df2.loc[(df2['parfam']==98)] #Filter to just this parfam\n",
    "df_98_min = df_98.index.min() #Get the first year for reindexing between election dates\n",
    "df_98_unique = df_98[~df_98.index.duplicated(keep='first')] #Remove dupes\n",
    "df_98_dupes = df_98[df_98.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_98 = pd.date_range(df_98_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_98_fill = df_98_unique.reindex(index=idx_98, method='ffill')\n",
    "df_98_final = df_98_fill.append(df_98_dupes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = pd.concat([df_10_final, df_30_final, df_40_final, df_50_final, df_60_final, df_70_final, df_80_final, df_90_final, df_98_final])\n",
    "finalDF.to_csv('bulgaria.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}