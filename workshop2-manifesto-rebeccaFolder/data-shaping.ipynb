{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            parfam countryname  per503  pervote electionDate  \\\n",
       "year                                                           \n",
       "1944-01-01      20      Sweden     0.0     10.3   1944-09-01   \n",
       "1944-01-01      30      Sweden     5.6     46.5   1944-09-01   \n",
       "1944-01-01      40      Sweden     1.6     12.9   1944-09-01   \n",
       "1944-01-01      60      Sweden     5.3     15.8   1944-09-01   \n",
       "1944-01-01      80      Sweden     0.0     13.6   1944-09-01   \n",
       "\n",
       "                                 partyname  environWeighted  \n",
       "year                                                         \n",
       "1944-01-01       Communist Party of Sweden             0.00  \n",
       "1944-01-01  Social Democratic Labour Party           260.40  \n",
       "1944-01-01                  People’s Party            20.64  \n",
       "1944-01-01                     Right Party            83.74  \n",
       "1944-01-01                  Agrarian Party             0.00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>parfam</th>\n      <th>countryname</th>\n      <th>per503</th>\n      <th>pervote</th>\n      <th>electionDate</th>\n      <th>partyname</th>\n      <th>environWeighted</th>\n    </tr>\n    <tr>\n      <th>year</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1944-01-01</th>\n      <td>20</td>\n      <td>Sweden</td>\n      <td>0.0</td>\n      <td>10.3</td>\n      <td>1944-09-01</td>\n      <td>Communist Party of Sweden</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1944-01-01</th>\n      <td>30</td>\n      <td>Sweden</td>\n      <td>5.6</td>\n      <td>46.5</td>\n      <td>1944-09-01</td>\n      <td>Social Democratic Labour Party</td>\n      <td>260.40</td>\n    </tr>\n    <tr>\n      <th>1944-01-01</th>\n      <td>40</td>\n      <td>Sweden</td>\n      <td>1.6</td>\n      <td>12.9</td>\n      <td>1944-09-01</td>\n      <td>People’s Party</td>\n      <td>20.64</td>\n    </tr>\n    <tr>\n      <th>1944-01-01</th>\n      <td>60</td>\n      <td>Sweden</td>\n      <td>5.3</td>\n      <td>15.8</td>\n      <td>1944-09-01</td>\n      <td>Right Party</td>\n      <td>83.74</td>\n    </tr>\n    <tr>\n      <th>1944-01-01</th>\n      <td>80</td>\n      <td>Sweden</td>\n      <td>0.0</td>\n      <td>13.6</td>\n      <td>1944-09-01</td>\n      <td>Agrarian Party</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"cleaned-data.csv\")\n",
    "\n",
    "df = df.set_index(pd.DatetimeIndex(df['year'])).drop(['year'], axis=1)\n",
    "df['electionDate'] = pd.to_datetime(df['electionDate'], format='%B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfams = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Austria\n",
    "\n",
    "df2 = df.loc[(df['countryname']=='Austria')] \n",
    "\n",
    "#Parfam 10\n",
    "df_10 = df2.loc[(df2['parfam']==10)] #Filter to just this parfam\n",
    "df_10_min = df_10.index.min() #Get the first year for reindexing between election dates\n",
    "df_10_unique = df_10[~df_10.index.duplicated(keep='first')] #Remove dupes\n",
    "df_10_dupes = df_10[df_10.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_10 = pd.date_range(df_10_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_10_fill = df_10_unique.reindex(index=idx_10, method='ffill') #add additional years & forward fill\n",
    "df_10_final = df_10_fill.append(df_10_dupes) #add back dupes\n",
    "\n",
    "##Parfam 20##\n",
    "df_20 = df2.loc[(df2['parfam']==20)] #Filter to just this parfam\n",
    "df_20_min = df_20.index.min() #Get the first year for reindexing between election dates\n",
    "df_20_unique = df_20[~df_20.index.duplicated(keep='first')] #Remove dupes\n",
    "df_20_dupes = df_20[df_20.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_20 = pd.date_range(df_20_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_20_fill = df_20_unique.reindex(index=idx_20, method='ffill')\n",
    "df_20_final = df_20_fill.append(df_20_dupes)\n",
    "\n",
    "##Parfam 30##\n",
    "df_30 = df2.loc[(df2['parfam']==30)] #Filter to just this parfam\n",
    "df_30_min = df_30.index.min() #Get the first year for reindexing between election dates\n",
    "df_30_unique = df_30[~df_30.index.duplicated(keep='first')] #Remove dupes\n",
    "df_30_dupes = df_30[df_30.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_30 = pd.date_range(df_30_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_30_fill = df_30_unique.reindex(index=idx_30, method='ffill')\n",
    "df_30_final = df_30_fill.append(df_30_dupes)\n",
    "\n",
    "##Parfam 40##\n",
    "df_40 = df2.loc[(df2['parfam']==40)] #Filter to just this parfam\n",
    "df_40_min = df_40.index.min() #Get the first year for reindexing between election dates\n",
    "df_40_unique = df_40[~df_40.index.duplicated(keep='first')] #Remove dupes\n",
    "df_40_dupes = df_40[df_40.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_40 = pd.date_range(df_40_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_40_fill = df_40_unique.reindex(index=idx_40, method='ffill')\n",
    "df_40_final = df_40_fill.append(df_40_dupes)\n",
    "\n",
    "##Parfam 50##\n",
    "df_50 = df2.loc[(df2['parfam']==50)] #Filter to just this parfam\n",
    "df_50_min = df_50.index.min() #Get the first year for reindexing between election dates\n",
    "df_50_unique = df_50[~df_50.index.duplicated(keep='first')] #Remove dupes\n",
    "df_50_dupes = df_50[df_50.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_50 = pd.date_range(df_50_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_50_fill = df_50_unique.reindex(index=idx_50, method='ffill')\n",
    "df_50_final = df_50_fill.append(df_50_dupes)\n",
    "\n",
    "##Parfam 60##\n",
    "df_60 = df2.loc[(df2['parfam']==60)] #Filter to just this parfam\n",
    "df_60_min = df_60.index.min() #Get the first year for reindexing between election dates\n",
    "df_60_unique = df_60[~df_60.index.duplicated(keep='first')] #Remove dupes\n",
    "df_60_dupes = df_60[df_60.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_60 = pd.date_range(df_60_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_60_fill = df_60_unique.reindex(index=idx_60, method='ffill')\n",
    "df_60_final = df_60_fill.append(df_60_dupes)\n",
    "\n",
    "##Parfam 70##\n",
    "df_70 = df2.loc[(df2['parfam']==70)] #Filter to just this parfam\n",
    "df_70_min = df_70.index.min() #Get the first year for reindexing between election dates\n",
    "df_70_unique = df_70[~df_70.index.duplicated(keep='first')] #Remove dupes\n",
    "df_70_dupes = df_70[df_70.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_70 = pd.date_range(df_70_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_70_fill = df_70_unique.reindex(index=idx_70, method='ffill')\n",
    "df_70_final = df_70_fill.append(df_70_dupes)\n",
    "\n",
    "##Parfam 80##\n",
    "df_80 = df2.loc[(df2['parfam']==80)] #Filter to just this parfam\n",
    "df_80_min = df_80.index.min() #Get the first year for reindexing between election dates\n",
    "df_80_unique = df_80[~df_80.index.duplicated(keep='first')] #Remove dupes\n",
    "df_80_dupes = df_80[df_80.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_80 = pd.date_range(df_80_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_80_fill = df_80_unique.reindex(index=idx_80, method='ffill')\n",
    "df_80_final = df_80_fill.append(df_80_dupes)\n",
    "\n",
    "##Parfam 90##\n",
    "df_90 = df2.loc[(df2['parfam']==90)] #Filter to just this parfam\n",
    "df_90_min = df_90.index.min() #Get the first year for reindexing between election dates\n",
    "df_90_unique = df_90[~df_90.index.duplicated(keep='first')] #Remove dupes\n",
    "df_90_dupes = df_90[df_90.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_90 = pd.date_range(df_90_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_90_fill = df_90_unique.reindex(index=idx_90, method='ffill')\n",
    "df_90_final = df_90_fill.append(df_90_dupes)\n",
    "\n",
    "##Parfam 95##\n",
    "df_95 = df2.loc[(df2['parfam']==95)] #Filter to just this parfam\n",
    "df_95_min = df_90.index.min() #Get the first year for reindexing between election dates\n",
    "df_90_unique = df_90[~df_90.index.duplicated(keep='first')] #Remove dupes\n",
    "df_90_dupes = df_90[df_90.index.duplicated(keep='first')] #Save dupes to add back later\n",
    "idx_90 = pd.date_range(df_90_min, '2020', freq='YS') #set the year range for reindexing\n",
    "df_90_fill = df_90_unique.reindex(index=idx_90, method='ffill')\n",
    "df_90_final = df_90_fill.append(df_90_dupes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_60_final' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-debef66361a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfFinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_10_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_20_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_30_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_40_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_50_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_60_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_70_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_80_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_90_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_95_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_98_final\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_60_final' is not defined"
     ]
    }
   ],
   "source": [
    "dfFinal = pd.concat([df_10_final, df_20_final, df_30_final, df_40_final, df_50_final, df_60_final, df_70_final, df_80_final, df_90_final, df_95_final, df_98_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}